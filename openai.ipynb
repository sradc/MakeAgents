{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_agents.gpt import completion\n",
    "from make_agents.make_agents import llm_func\n",
    "\n",
    "\n",
    "from graphviz import Digraph\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = completion(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant that will explain everything and not hold back information from the user.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"Fish: I am a fish.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Yes, I can see you are a fish.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Dog: I am a cat.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"No, you are a dog.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Eagle: I am a bird.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Yes, I can see you are a bird.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Toad: I am a beatle.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"No, you are a toad, not a beetle.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Toad: Corrent, how did you know that I'm a toad?\"},\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"As an AI, I don't have the physical ability to see or observe the world around me. However, I can provide information based on what you tell me. In this case, you mentioned that you are a toad, so I am giving you a response based on that information.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Toad: I didn't mention that I was a toad did I? Can you please tell me what I said?\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"314pt\" height=\"404pt\"\n",
       " viewBox=\"0.00 0.00 314.23 404.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 400)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-400 310.23,-400 310.23,4 -4,4\"/>\n",
       "<!-- Start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Start</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"200.94\" cy=\"-378\" rx=\"34.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.94\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">Start</text>\n",
       "</g>\n",
       "<!-- get_system_prompt -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>get_system_prompt</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"200.94\" cy=\"-306\" rx=\"102.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.94\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">get_system_prompt</text>\n",
       "</g>\n",
       "<!-- Start&#45;&gt;get_system_prompt -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Start&#45;&gt;get_system_prompt</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M200.94,-359.7C200.94,-351.98 200.94,-342.71 200.94,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"204.44,-334.1 200.94,-324.1 197.44,-334.1 204.44,-334.1\"/>\n",
       "</g>\n",
       "<!-- ask_user_a_question -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>ask_user_a_question</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"200.94\" cy=\"-234\" rx=\"105.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.94\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">ask_user_a_question</text>\n",
       "</g>\n",
       "<!-- get_system_prompt&#45;&gt;ask_user_a_question -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>get_system_prompt&#45;&gt;ask_user_a_question</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M200.94,-287.7C200.94,-279.98 200.94,-270.71 200.94,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"204.44,-262.1 200.94,-252.1 197.44,-262.1 204.44,-262.1\"/>\n",
       "</g>\n",
       "<!-- ask_clarifying_question -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>ask_clarifying_question</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"118.94\" cy=\"-162\" rx=\"118.88\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.94\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">ask_clarifying_question</text>\n",
       "</g>\n",
       "<!-- ask_user_a_question&#45;&gt;ask_clarifying_question -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>ask_user_a_question&#45;&gt;ask_clarifying_question</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M181.09,-216.05C170.72,-207.2 157.85,-196.22 146.53,-186.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"148.48,-183.62 138.61,-179.79 143.94,-188.94 148.48,-183.62\"/>\n",
       "</g>\n",
       "<!-- search_internet -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>search_internet</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"118.94\" cy=\"-90\" rx=\"83.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.94\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">search_internet</text>\n",
       "</g>\n",
       "<!-- ask_user_a_question&#45;&gt;search_internet -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>ask_user_a_question&#45;&gt;search_internet</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.7,-216.6C243.77,-207.66 257.76,-195.27 264.94,-180 271.75,-165.52 274.12,-157.1 264.94,-144 249.91,-122.56 225.28,-109.75 200.48,-102.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"201.2,-98.69 190.63,-99.35 199.3,-105.43 201.2,-98.69\"/>\n",
       "</g>\n",
       "<!-- ask_clarifying_question&#45;&gt;ask_clarifying_question -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>ask_clarifying_question&#45;&gt;ask_clarifying_question</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M198.43,-175.43C229.73,-176.11 255.88,-171.63 255.88,-162 255.88,-153.42 235.14,-148.93 208.49,-148.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"208.42,-145.03 198.43,-148.57 208.44,-152.03 208.42,-145.03\"/>\n",
       "</g>\n",
       "<!-- ask_clarifying_question&#45;&gt;search_internet -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>ask_clarifying_question&#45;&gt;search_internet</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M113.02,-143.7C112.23,-135.98 112,-126.71 112.34,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"115.84,-118.32 113.04,-108.1 108.85,-117.84 115.84,-118.32\"/>\n",
       "</g>\n",
       "<!-- search_internet&#45;&gt;ask_clarifying_question -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>search_internet&#45;&gt;ask_clarifying_question</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M124.83,-108.1C125.64,-115.79 125.88,-125.05 125.54,-133.67\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"122.05,-133.48 124.86,-143.7 129.03,-133.96 122.05,-133.48\"/>\n",
       "</g>\n",
       "<!-- give_final_answer -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>give_final_answer</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"118.94\" cy=\"-18\" rx=\"92.88\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.94\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">give_final_answer</text>\n",
       "</g>\n",
       "<!-- search_internet&#45;&gt;give_final_answer -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>search_internet&#45;&gt;give_final_answer</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M118.94,-71.7C118.94,-63.98 118.94,-54.71 118.94,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"122.44,-46.1 118.94,-36.1 115.44,-46.1 122.44,-46.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f1b3fc21870>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: no \"view\" rule for type \"application/pdf\" passed its test case\n",
      "       (for more information, add \"--debug=1\" on the command line)\n"
     ]
    }
   ],
   "source": [
    "class Start:\n",
    "    # initialises empty list of messages\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_system_prompt() -> str:\n",
    "    return \"You will ask the user what they want and assist them\"\n",
    "\n",
    "\n",
    "class AskUserAQuestionArg(BaseModel):\n",
    "    question: str = Field(description=\"Question to ask user\")\n",
    "\n",
    "\n",
    "@llm_func\n",
    "def ask_user_a_question(arg: AskUserAQuestionArg) -> str:\n",
    "    \"\"\"Ask user a question and get their response\"\"\"\n",
    "    return \"user response here\"\n",
    "\n",
    "\n",
    "@llm_func\n",
    "def ask_clarifying_question(arg: AskUserAQuestionArg) -> str:\n",
    "    \"\"\"If the user's response is not clear, ask a clarifying question\"\"\"\n",
    "    return \"user response here\"\n",
    "\n",
    "\n",
    "class SearchInternetArg(BaseModel):\n",
    "    query: str = Field(description=\"Search query\")\n",
    "\n",
    "\n",
    "@llm_func\n",
    "def search_internet(arg: AskUserAQuestionArg) -> str:\n",
    "    \"\"\"Ask user a question and get their response\"\"\"\n",
    "    return \"user response here\"\n",
    "\n",
    "\n",
    "class GiveFinalAnswerArg(BaseModel):\n",
    "    final_answer: str = Field(description=\"Final answer to tell user\")\n",
    "\n",
    "\n",
    "@llm_func\n",
    "def give_final_answer(arg: GiveFinalAnswerArg) -> str:\n",
    "    \"\"\"Ask user a question and get their response\"\"\"\n",
    "    print(arg.final_answer)\n",
    "\n",
    "\n",
    "graph = {\n",
    "    Start: get_system_prompt,\n",
    "    get_system_prompt: ask_user_a_question,\n",
    "    ask_user_a_question: [search_internet, ask_clarifying_question],\n",
    "    ask_clarifying_question: [search_internet, ask_clarifying_question],\n",
    "    search_internet: [give_final_answer, ask_clarifying_question],\n",
    "}\n",
    "\n",
    "# visualise \"graph\" graph using graphviz\n",
    "dot = Digraph(comment=\"graph\")\n",
    "for node in graph:\n",
    "    dot.node(node.__name__, node.__name__)\n",
    "for node, children in graph.items():\n",
    "    if isinstance(children, list):\n",
    "        for child in children:\n",
    "            dot.edge(node.__name__, child.__name__)\n",
    "    else:\n",
    "        dot.edge(node.__name__, children.__name__)\n",
    "dot.render(\"graph.gv\", view=True)\n",
    "dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Start:\n",
    "    pass\n",
    "\n",
    "\n",
    "class Node:\n",
    "    pass\n",
    "\n",
    "\n",
    "start = Start()\n",
    "ask_for_question = Node(after=start)\n",
    "run_query = Node(after=ask_for_question)\n",
    "ask_clarifying_question = Node(after=ask_for_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetUserInputArg(BaseModel):\n",
    "    question: str = Field(description=\"Question to ask user.\")\n",
    "\n",
    "\n",
    "@llm_func\n",
    "def get_user_input(arg: GetUserInputArg):\n",
    "    \"Get user inputattach_description_for_llm\"\n",
    "    user_response = input(f\"{arg.question} \").strip()\n",
    "    return user_response\n",
    "\n",
    "\n",
    "get_user_input.description_for_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"}]\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "response = completion(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    ")\n",
    "response_message = response[\"choices\"][0][\"message\"]\n",
    "response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[convert_to_openai_function(get_current_weather)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetCurrentWeatherArg(BaseModel):\n",
    "    location: str = Field(description=\"The city and state, e.g. San Francisco, CA\")\n",
    "    unit: Literal[\"celsius\", \"fahrenheit\"] = Field(\n",
    "        description=\"The unit of temperature to return.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_current_weather(arg: GetCurrentWeatherArg):\n",
    "    \"Get the current weather in a given location\"\n",
    "    print(arg.location, arg.unit)\n",
    "    if arg.unit == \"celsius\":\n",
    "        return \"It's 20 degrees celcius.\"\n",
    "    else:\n",
    "        return \"It's 68 degrees Farenheit.\"\n",
    "\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"}]\n",
    "response = completion(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=[convert_to_openai_function(get_current_weather)],\n",
    "    function_call={\"name\": get_current_weather.__name__},  # force the function call\n",
    ")\n",
    "assistant_message = response[\"choices\"][0][\"message\"]\n",
    "function_call = assistant_message[\"function_call\"]\n",
    "assert function_call[\"name\"] == get_current_weather.__name__\n",
    "messages.append(assistant_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg = GetCurrentWeatherArg(**json.loads(function_call[\"arguments\"]))\n",
    "function_response = get_current_weather(arg)\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"function\",\n",
    "        \"name\": get_current_weather.__name__,\n",
    "        \"content\": function_response,\n",
    "    }\n",
    ")  # extend conversation with function response\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = completion(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=[convert_to_openai_function(get_current_weather)],\n",
    ")\n",
    "assistant_message = response[\"choices\"][0][\"message\"]\n",
    "assistant_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note! It expects the function call to still be there, otherwise it doesn't respond as expected (says \"I don't have real-time data.\")\n",
    "response = completion(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    ")\n",
    "assistant_message = response[\"choices\"][0][\"message\"]\n",
    "assistant_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetUserInputArg(BaseModel):\n",
    "    prompt: str = Field(description=\"The prompt shown when asking for input.\")\n",
    "\n",
    "\n",
    "def get_user_input(arg: GetUserInputArg):\n",
    "    \"Get the current weather in a given location\"\n",
    "    user_response = input(f\"{arg.prompt} \").strip()\n",
    "    return {\"user_response\": user_response}\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are an onboarding assistant. Please ask for the users first name. Once you have got it, ask for their second name. Finally, playfully insult them using their name.\",\n",
    "    },\n",
    "]\n",
    "response = completion(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=[convert_to_openai_function(get_user_input)],\n",
    "    function_call={\"name\": get_user_input.__name__},  # force the function call\n",
    ")\n",
    "assistant_message = response[\"choices\"][0][\"message\"]\n",
    "function_call = assistant_message[\"function_call\"]\n",
    "assert function_call[\"name\"] == get_user_input.__name__\n",
    "messages.append(assistant_message)\n",
    "arg = GetUserInputArg(**json.loads(function_call[\"arguments\"]))\n",
    "function_response = get_user_input(arg)\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"function\",\n",
    "        \"name\": get_user_input.__name__,\n",
    "        \"content\": json.dumps(function_response)\n",
    "        if not type(function_response) == str\n",
    "        else function_response,\n",
    "    }\n",
    ")  # extend conversation with function response\n",
    "\n",
    "\n",
    "# Allow it to ask again\n",
    "response = completion(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=[convert_to_openai_function(get_user_input)],\n",
    "    function_call={\"name\": get_user_input.__name__},  # force the function call\n",
    ")\n",
    "assistant_message = response[\"choices\"][0][\"message\"]\n",
    "function_call = assistant_message[\"function_call\"]\n",
    "assert function_call[\"name\"] == get_user_input.__name__\n",
    "messages.append(assistant_message)\n",
    "arg = GetUserInputArg(**json.loads(function_call[\"arguments\"]))\n",
    "function_response = get_user_input(arg)\n",
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"function\",\n",
    "        \"name\": get_user_input.__name__,\n",
    "        \"content\": json.dumps(function_response)\n",
    "        if not type(function_response) == str\n",
    "        else function_response,\n",
    "    }\n",
    ")  # extend conversation with function response\n",
    "\n",
    "response = completion(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    ")\n",
    "messages.append(response[\"choices\"][0][\"message\"])\n",
    "messages"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
